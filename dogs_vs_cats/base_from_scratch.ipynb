{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df9024-56d1-44bd-b2af-73790793c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = \"/home/a.makarchuk@rit.va/Desktop/kaggle-CV-best11/dogs_vs_cats/data/\"\n",
    "%cd $PATH_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26222e9c-95d8-4dfe-b672-53b9b5316162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd_ = pd.read_csv(PATH_DATA + \"sampleSubmission.csv\")\n",
    "list_train_imgs = os.listdir(PATH_DATA + \"train\")\n",
    "list_test_imgs = os.listdir(PATH_DATA + \"test1\")\n",
    "print(sum(pd_[\"label\"] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b419b92c-d4c4-4d4a-91bb-b82d1921aed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "image_size = (128, 128)\n",
    "\n",
    "rand_img_train_path = PATH_DATA + \"train/\" + random.choice(list_train_imgs)\n",
    "img = plt.imread(rand_img_train_path)\n",
    "img = cv2.resize(img, image_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "print(rand_img_train_path)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4b3a99-2e3a-47c2-ae07-5ded60f99b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def load_and_transform_img(path_img, image_size):\n",
    "    img_name = path_img.split(\"/\")[-1]\n",
    "    label = 1 if img_name.split(\".\")[0] == \"dog\" else 0\n",
    "    img = plt.imread(path_img)\n",
    "    img = cv2.resize(img, image_size, interpolation=cv2.INTER_AREA)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    return torch.from_numpy(img).float(), torch.from_numpy(np.array(label)).float()\n",
    "\n",
    "\n",
    "def generate_batch(list_imgs_path, batch_size):\n",
    "    curr_id = 0\n",
    "    while curr_id + batch_size < len(list_imgs_path):\n",
    "        images_tensor_list = list()\n",
    "        labels_tensor_list = list()\n",
    "        for i in range(batch_size):\n",
    "            img_tensor, label = load_and_transform_img(\n",
    "                PATH_DATA + \"train/\" + list_imgs_path[curr_id + i], image_size\n",
    "            )\n",
    "            images_tensor_list.append(img_tensor)\n",
    "            labels_tensor_list.append(label)\n",
    "        yield torch.stack(images_tensor_list), torch.stack(labels_tensor_list).unsqueeze(-1)\n",
    "        curr_id += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0c9e0e-669d-4d2b-923a-96335e8ffa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check image loader with the generator\n",
    "\n",
    "\n",
    "for i, (stacked_imgs, stacked_lbls) in enumerate(generate_batch(list_train_imgs, 1)):\n",
    "    img = stacked_imgs.squeeze().numpy()\n",
    "    label = stacked_lbls.squeeze().numpy()\n",
    "    img = (img * 255).astype(int)\n",
    "    print(label)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76851213-ff24-47d6-a2dd-4483784757be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, image_size=(128, 128)):\n",
    "        super().__init__()\n",
    "        h, w = image_size\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.base_classifier = nn.Sequential(\n",
    "            nn.BatchNorm1d(h * w * 3),\n",
    "            nn.Linear(h * w * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        out_logits = self.base_classifier(x)\n",
    "        return out_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33a7cb-df29-4c53-9090-3b1517792c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = NeuralNetwork().to(device)\n",
    "sigmoid = nn.Sigmoid()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "train_ratio = 0.85\n",
    "list_imgs = list_train_imgs[:]\n",
    "random.shuffle(list_imgs)\n",
    "list_train_imgs = list_imgs[: int(len(list_imgs) * train_ratio)]\n",
    "list_val_imgs = list_imgs[int(len(list_imgs) * train_ratio) : len(list_imgs)]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    model.train()\n",
    "    for idx, (batch_imgs, lbl) in tqdm(\n",
    "        enumerate(generate_batch(list_train_imgs, batch_size)),\n",
    "        total=len(list_train_imgs) // batch_size,\n",
    "    ):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        lbl = lbl.to(device)\n",
    "        logits = model(batch_imgs)\n",
    "\n",
    "        output = loss(sigmoid(logits), lbl)\n",
    "        output.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        predicted_probs = sigmoid(logits).detach().cpu().numpy()\n",
    "        predicted_labels = (predicted_probs > 0.5).astype(float)\n",
    "\n",
    "        if idx % 50 == 0:\n",
    "            print(\n",
    "                f\"Train F1-score: {f1_score(lbl.detach().cpu().numpy(), predicted_labels):.4f} Train Loss: {output:.4f}\"\n",
    "            )\n",
    "\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        for batch_imgs, lbl in tqdm(\n",
    "            generate_batch(list_val_imgs, batch_size), total=len(list_val_imgs) // batch_size\n",
    "        ):\n",
    "            batch_imgs = batch_imgs.to(device)\n",
    "            lbl = lbl.to(device)\n",
    "\n",
    "            logits = model(batch_imgs)\n",
    "            val_loss.append(loss(sigmoid(logits), lbl).detach().cpu().numpy())\n",
    "            predicted_probs = sigmoid(logits).detach().cpu().numpy()\n",
    "            predicted_labels = (predicted_probs > 0.5).astype(float)\n",
    "\n",
    "            val_preds.extend(predicted_labels)\n",
    "            val_labels.extend(lbl.detach().cpu().numpy())\n",
    "\n",
    "    val_f1 = f1_score(val_labels, val_preds)\n",
    "    print(f\"Validation F1-score: {val_f1:.4f} Validation Loss: {np.mean(val_loss):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f694201f-8181-487b-9cf7-8d7965df87aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_preds = []\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "pd_test = pd.DataFrame(columns=[\"id\", \"label\"])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for path_img in tqdm(list_test_imgs, total=len(list_test_imgs)):\n",
    "        id_img = path_img.split(\".\")[0]\n",
    "        img = plt.imread(PATH_DATA + \"test1/\" + path_img)\n",
    "        img = cv2.resize(img, image_size, interpolation=cv2.INTER_AREA)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        logits = model(torch.from_numpy(img).unsqueeze(0))\n",
    "        pd_test.loc[len(pd_test)] = [id_img, sigmoid(logits).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100200bb-12a4-4212-9b46-66fac7236929",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41649804-4c4e-467f-974f-b941c63e0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_test.to_csv(\"base_from_scratch.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_cv_best11",
   "language": "python",
   "name": "kaggle_cv_best11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
